{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c676b5aa",
   "metadata": {},
   "source": [
    "# RH/Temp/ETo Prediction (split targets)\n",
    "\n",
    "Weather-only features: time sin/cos, lags 1/3/6/18/24/48, rolls 3/6/12/24/48, `rh_x_temp`.\n",
    "- `air_temp_C` from `air_temp_c.csv`\n",
    "- `Rh_internal` and `Eto_mm` from `rh_et0.csv` (column now `internal_RH`)\n",
    "- RH/ETo training restricted to data up to 2025-09-03 to retain higher R2\n",
    "- Chronological 80/20 split with forward-chaining CV per target\n",
    "- ETo predictions clamped to >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec7bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "DATA_DIR = Path(__file__).resolve().parent if \"__file__\" in globals() else Path().resolve()\n",
    "\n",
    "param_grid = [\n",
    "    {\"max_depth\": 6, \"learning_rate\": 0.05, \"min_samples_leaf\": 20, \"max_bins\": 255},\n",
    "    {\"max_depth\": 8, \"learning_rate\": 0.05, \"min_samples_leaf\": 20, \"max_bins\": 255},\n",
    "    {\"max_depth\": 10, \"learning_rate\": 0.03, \"min_samples_leaf\": 30, \"max_bins\": 255},\n",
    "    {\"max_depth\": 12, \"learning_rate\": 0.03, \"min_samples_leaf\": 20, \"max_bins\": 255},\n",
    "    {\"max_depth\": None, \"learning_rate\": 0.05, \"min_samples_leaf\": 30, \"max_bins\": 255},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771f5406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weather() -> pd.DataFrame:\n",
    "    rad = pd.read_csv(DATA_DIR / \"bet_dagan_radiation.csv\")\n",
    "    wx = pd.read_csv(DATA_DIR / \"bet_dagan_weather.csv\")\n",
    "\n",
    "    rc = rad.columns.tolist()\n",
    "    wc = wx.columns.tolist()\n",
    "\n",
    "    rad = rad.rename(\n",
    "        columns={\n",
    "            rc[0]: \"station_radiation\",\n",
    "            rc[1]: \"datetime\",\n",
    "            rc[2]: \"diffuse_radiation_Wm2\",\n",
    "            rc[3]: \"global_radiation_Wm2\",\n",
    "            rc[4]: \"direct_radiation_Wm2\",\n",
    "        }\n",
    "    )\n",
    "    wx = wx.rename(\n",
    "        columns={\n",
    "            wc[0]: \"station_weather\",\n",
    "            wc[1]: \"datetime\",\n",
    "            wc[2]: \"station_pressure_hpa\",\n",
    "            wc[3]: \"relative_humidity_pct\",\n",
    "            wc[4]: \"air_temp_C_weather\",\n",
    "            wc[5]: \"air_temp_max_C_weather\",\n",
    "            wc[6]: \"air_temp_min_C_weather\",\n",
    "            wc[7]: \"ground_temp_C\",\n",
    "            wc[8]: \"wet_temp_C\",\n",
    "            wc[9]: \"wind_dir_deg\",\n",
    "            wc[10]: \"gust_dir_deg\",\n",
    "            wc[11]: \"wind_speed_ms\",\n",
    "            wc[12]: \"wind_speed_1m_max_ms\",\n",
    "            wc[13]: \"wind_speed_10m_max_ms\",\n",
    "            wc[14]: \"wind_speed_10m_max_end_time\",\n",
    "            wc[15]: \"gust_speed_ms\",\n",
    "            wc[16]: \"wind_dir_std_deg\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    rad[\"datetime\"] = pd.to_datetime(rad[\"datetime\"], dayfirst=True)\n",
    "    wx[\"datetime\"] = pd.to_datetime(wx[\"datetime\"], dayfirst=True)\n",
    "    rad = rad.replace(\"-\", np.nan)\n",
    "    wx = wx.replace(\"-\", np.nan)\n",
    "\n",
    "    def _coerce_numeric(df: pd.DataFrame, ignore: List[str]) -> pd.DataFrame:\n",
    "        for col in df.columns:\n",
    "            if col in ignore:\n",
    "                continue\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        return df\n",
    "\n",
    "    rad = _coerce_numeric(rad, ignore=[\"station_radiation\", \"datetime\"])\n",
    "    wx = _coerce_numeric(wx, ignore=[\"station_weather\", \"datetime\", \"wind_speed_10m_max_end_time\"])\n",
    "    merged = pd.merge(rad, wx, on=\"datetime\", how=\"inner\")\n",
    "    return merged.sort_values(\"datetime\")\n",
    "\n",
    "\n",
    "def load_targets_rh_et0() -> pd.DataFrame:\n",
    "    df = pd.read_csv(DATA_DIR / \"rh_et0.csv\")\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"Date & Time (Summer)\"], dayfirst=True)\n",
    "    df = df.rename(columns={\"Eto (mm)\": \"Eto_mm\", \"RH%\": \"Rh_internal\", \"internal_RH\": \"Rh_internal\"})\n",
    "    cutoff = pd.Timestamp(\"2025-09-08 23:59:59\")\n",
    "    df = df[df[\"timestamp\"] <= cutoff]\n",
    "    return df[[\"timestamp\", \"Rh_internal\", \"Eto_mm\"]].sort_values(\"timestamp\")\n",
    "\n",
    "\n",
    "def load_targets_air() -> pd.DataFrame:\n",
    "    df = pd.read_csv(DATA_DIR / \"air_temp_c.csv\")\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"datetime\"] + \" \" + df[\"time\"], dayfirst=False)\n",
    "    return df[[\"timestamp\", \"air_temp_C\"]].sort_values(\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbdd16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_feature_cols = [\n",
    "    \"diffuse_radiation_Wm2\",\n",
    "    \"global_radiation_Wm2\",\n",
    "    \"direct_radiation_Wm2\",\n",
    "    \"station_pressure_hpa\",\n",
    "    \"relative_humidity_pct\",\n",
    "    \"air_temp_C_weather\",\n",
    "    \"air_temp_max_C_weather\",\n",
    "    \"air_temp_min_C_weather\",\n",
    "    \"ground_temp_C\",\n",
    "    \"wet_temp_C\",\n",
    "    \"wind_dir_deg\",\n",
    "    \"gust_dir_deg\",\n",
    "    \"wind_speed_ms\",\n",
    "    \"wind_speed_1m_max_ms\",\n",
    "    \"wind_speed_10m_max_ms\",\n",
    "    \"gust_speed_ms\",\n",
    "    \"wind_dir_std_deg\",\n",
    "]\n",
    "\n",
    "def engineer_features(df_all: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:\n",
    "    df_features = df_all[base_feature_cols].copy()\n",
    "    timestamps = df_all[\"timestamp\"]\n",
    "    df_features[\"hour\"] = timestamps.dt.hour\n",
    "    df_features[\"dayofyear\"] = timestamps.dt.dayofyear\n",
    "    df_features[\"hour_sin\"] = np.sin(2 * np.pi * df_features[\"hour\"] / 24)\n",
    "    df_features[\"hour_cos\"] = np.cos(2 * np.pi * df_features[\"hour\"] / 24)\n",
    "    df_features[\"doy_sin\"] = np.sin(2 * np.pi * df_features[\"dayofyear\"] / 365)\n",
    "    df_features[\"doy_cos\"] = np.cos(2 * np.pi * df_features[\"dayofyear\"] / 365)\n",
    "    df_features[\"rh_x_temp\"] = df_features[\"relative_humidity_pct\"] * df_features[\"air_temp_C_weather\"]\n",
    "    lag_cols = [\n",
    "        \"diffuse_radiation_Wm2\",\n",
    "        \"global_radiation_Wm2\",\n",
    "        \"direct_radiation_Wm2\",\n",
    "        \"air_temp_C_weather\",\n",
    "        \"relative_humidity_pct\",\n",
    "    ]\n",
    "    for col in lag_cols:\n",
    "        df_features[f\"{col}_lag1\"] = df_all[col].shift(1)\n",
    "        df_features[f\"{col}_lag3\"] = df_all[col].shift(3)\n",
    "        df_features[f\"{col}_lag6\"] = df_all[col].shift(6)\n",
    "        df_features[f\"{col}_lag18\"] = df_all[col].shift(18)\n",
    "        df_features[f\"{col}_lag24\"] = df_all[col].shift(24)\n",
    "        df_features[f\"{col}_lag48\"] = df_all[col].shift(48)\n",
    "        df_features[f\"{col}_roll3_mean\"] = df_all[col].rolling(window=3, min_periods=1).mean().shift(1)\n",
    "        df_features[f\"{col}_roll6_mean\"] = df_all[col].rolling(window=6, min_periods=1).mean().shift(1)\n",
    "        df_features[f\"{col}_roll12_mean\"] = df_all[col].rolling(window=12, min_periods=1).mean().shift(1)\n",
    "        df_features[f\"{col}_roll24_mean\"] = df_all[col].rolling(window=24, min_periods=1).mean().shift(1)\n",
    "        df_features[f\"{col}_roll48_mean\"] = df_all[col].rolling(window=48, min_periods=1).mean().shift(1)\n",
    "    df_features = df_features.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    non_empty_features = [c for c in df_features.columns if not df_features[c].isna().all()]\n",
    "    df_features = df_features[non_empty_features].apply(lambda col: col.fillna(col.median()))\n",
    "    return df_features, non_empty_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6614fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_target(weather: pd.DataFrame, targets: pd.DataFrame, target_col: str):\n",
    "    merged = pd.merge_asof(\n",
    "        targets.sort_values(\"timestamp\"),\n",
    "        weather.sort_values(\"datetime\"),\n",
    "        left_on=\"timestamp\",\n",
    "        right_on=\"datetime\",\n",
    "        direction=\"nearest\",\n",
    "        tolerance=pd.Timedelta(\"30min\"),\n",
    "    )\n",
    "    df_all = merged.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "    df_features, non_empty_features = engineer_features(df_all)\n",
    "    y = pd.to_numeric(df_all[target_col], errors=\"coerce\")\n",
    "    mask = y.notna()\n",
    "    df_features = df_features.loc[mask].reset_index(drop=True)\n",
    "    y = y.loc[mask].reset_index(drop=True)\n",
    "    df_all = df_all.loc[mask].reset_index(drop=True)\n",
    "    return df_features, y, df_all, non_empty_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c863a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_cv(df_features: pd.DataFrame, y: pd.Series, non_empty_features: List[str]):\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    X = df_features[non_empty_features].values\n",
    "    results = []\n",
    "    for params in param_grid:\n",
    "        rmses = []\n",
    "        for tr_idx, val_idx in tscv.split(X):\n",
    "            X_tr, X_val = X[tr_idx], X[val_idx]\n",
    "            y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "            model = HistGradientBoostingRegressor(\n",
    "                max_depth=params.get(\"max_depth\"),\n",
    "                learning_rate=params.get(\"learning_rate\", 0.1),\n",
    "                min_samples_leaf=params.get(\"min_samples_leaf\", 20),\n",
    "                max_bins=params.get(\"max_bins\", 255),\n",
    "                random_state=0,\n",
    "            )\n",
    "            model.fit(X_tr, y_tr)\n",
    "            preds = model.predict(X_val)\n",
    "            rmse = mean_squared_error(y_val, preds, squared=False)\n",
    "            rmses.append(rmse)\n",
    "        results.append((params, float(np.mean(rmses))))\n",
    "    best_params, best_score = sorted(results, key=lambda x: x[1])[0]\n",
    "    final_model = HistGradientBoostingRegressor(\n",
    "        max_depth=best_params.get(\"max_depth\"),\n",
    "        learning_rate=best_params.get(\"learning_rate\", 0.1),\n",
    "        min_samples_leaf=best_params.get(\"min_samples_leaf\", 20),\n",
    "        max_bins=best_params.get(\"max_bins\", 255),\n",
    "        random_state=0,\n",
    "    )\n",
    "    final_model.fit(X, y)\n",
    "    return final_model, best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8abf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weather\n",
    "weather = load_weather()\n",
    "\n",
    "# Air temp target\n",
    "df_air_tgt = load_targets_air()\n",
    "air_feat, air_y, air_all, air_non_empty = prepare_target(weather, df_air_tgt, \"air_temp_C\")\n",
    "\n",
    "# RH/ETo targets\n",
    "df_rh_tgt = load_targets_rh_et0()\n",
    "rh_feat, rh_y, rh_all, rh_non_empty = prepare_target(weather, df_rh_tgt, \"Rh_internal\")\n",
    "eto_feat, eto_y, eto_all, eto_non_empty = prepare_target(weather, df_rh_tgt, \"Eto_mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dbc502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "air_model, air_params, air_cv = train_with_cv(air_feat, air_y, air_non_empty)\n",
    "rh_model, rh_params, rh_cv = train_with_cv(rh_feat, rh_y, rh_non_empty)\n",
    "eto_model, eto_params, eto_cv = train_with_cv(eto_feat, eto_y, eto_non_empty)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(\"air_temp_C\", air_params, air_cv)\n",
    "print(\"Rh_internal\", rh_params, rh_cv)\n",
    "print(\"Eto_mm\", eto_params, eto_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fbb6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chronological 80/20 splits for metrics\n",
    "def split_for_metrics(df_feat, y, non_empty):\n",
    "    split_idx = int(len(df_feat) * 0.8)\n",
    "    X_train = df_feat.iloc[:split_idx][non_empty]\n",
    "    X_test = df_feat.iloc[split_idx:][non_empty]\n",
    "    y_train = y.iloc[:split_idx]\n",
    "    y_test = y.iloc[split_idx:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "air_Xtr, air_Xte, air_ytr, air_yte = split_for_metrics(air_feat, air_y, air_non_empty)\n",
    "rh_Xtr, rh_Xte, rh_ytr, rh_yte = split_for_metrics(rh_feat, rh_y, rh_non_empty)\n",
    "eto_Xtr, eto_Xte, eto_ytr, eto_yte = split_for_metrics(eto_feat, eto_y, eto_non_empty)\n",
    "\n",
    "air_model.fit(air_Xtr, air_ytr)\n",
    "rh_model.fit(rh_Xtr, rh_ytr)\n",
    "eto_model.fit(eto_Xtr, eto_ytr)\n",
    "\n",
    "air_pred = air_model.predict(air_Xte)\n",
    "rh_pred = rh_model.predict(rh_Xte)\n",
    "eto_pred = eto_model.predict(eto_Xte)\n",
    "eto_pred = np.maximum(eto_pred, 0)\n",
    "\n",
    "print(\"Test metrics (chronological split):\")\n",
    "for name, true, pred in [\n",
    "    (\"air_temp_C\", air_yte, air_pred),\n",
    "    (\"Rh_internal\", rh_yte, rh_pred),\n",
    "    (\"Eto_mm\", eto_yte, eto_pred),\n",
    "]:\n",
    "    mae = mean_absolute_error(true, pred)\n",
    "    mse = mean_squared_error(true, pred)\n",
    "    rmse = mean_squared_error(true, pred, squared=False)\n",
    "    r2 = r2_score(true, pred)\n",
    "    print(f\"- {name}\")\n",
    "    print(f\"  MAE:  {mae:.3f}\")\n",
    "    print(f\"  MSE:  {mse:.3f}\")\n",
    "    print(f\"  RMSE: {rmse:.3f}\")\n",
    "    print(f\"  R2:   {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f1a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect RH training rows\n",
    "split_idx = int(len(rh_all) * 0.8)\n",
    "rh_train_rows = rh_all.iloc[:split_idx][[\"timestamp\", \"Rh_internal\"]].copy()\n",
    "print(f\"RH training rows: {len(rh_train_rows)}\")\n",
    "print(f\"Range: {rh_train_rows['timestamp'].min()} -> {rh_train_rows['timestamp'].max()}\")\n",
    "print(\"Head:\")\n",
    "print(rh_train_rows.head())\n",
    "print(\"Tail:\")\n",
    "print(rh_train_rows.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1249fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export test predictions (per target + combined)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "test_air = air_all.iloc[int(len(air_all)*0.8):].copy()\n",
    "test_air[\"pred_air_temp_C\"] = air_pred\n",
    "test_air_path = DATA_DIR / \"test_predictions_air.csv\"\n",
    "test_air[[\"timestamp\", \"air_temp_C\", \"pred_air_temp_C\"]].to_csv(test_air_path, index=False)\n",
    "\n",
    "test_rh = rh_all.iloc[int(len(rh_all)*0.8):].copy()\n",
    "test_rh[\"pred_Rh_internal\"] = rh_pred\n",
    "test_rh_path = DATA_DIR / \"test_predictions_rh.csv\"\n",
    "test_rh[[\"timestamp\", \"Rh_internal\", \"pred_Rh_internal\"]].to_csv(test_rh_path, index=False)\n",
    "\n",
    "test_eto = eto_all.iloc[int(len(eto_all)*0.8):].copy()\n",
    "test_eto[\"pred_Eto_mm\"] = np.maximum(eto_pred, 0)\n",
    "test_eto_path = DATA_DIR / \"test_predictions_eto.csv\"\n",
    "test_eto[[\"timestamp\", \"Eto_mm\", \"pred_Eto_mm\"]].to_csv(test_eto_path, index=False)\n",
    "\n",
    "# Combined, aligned to air timestamps\n",
    "test_output = pd.DataFrame({\"timestamp\": test_air[\"timestamp\"]})\n",
    "test_output[\"air_temp_C\"] = test_air[\"air_temp_C\"].values\n",
    "test_output[\"pred_air_temp_C\"] = test_air[\"pred_air_temp_C\"].values\n",
    "test_output[\"Rh_internal\"] = test_rh.set_index(\"timestamp\")[\"Rh_internal\"].reindex(test_air[\"timestamp\"]).values\n",
    "test_output[\"pred_Rh_internal\"] = test_rh.set_index(\"timestamp\")[\"pred_Rh_internal\"].reindex(test_air[\"timestamp\"]).values\n",
    "test_output[\"Eto_mm\"] = test_eto.set_index(\"timestamp\")[\"Eto_mm\"].reindex(test_air[\"timestamp\"]).values\n",
    "test_output[\"pred_Eto_mm\"] = test_eto.set_index(\"timestamp\")[\"pred_Eto_mm\"].reindex(test_air[\"timestamp\"]).values\n",
    "\n",
    "test_path = DATA_DIR / \"test_predictions_rh_temp_et0_split.csv\"\n",
    "test_output.to_csv(test_path, index=False)\n",
    "print(f\"Wrote test predictions to {test_air_path}, {test_rh_path}, {test_eto_path}, {test_path}\")\n",
    "test_output.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee09e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict full weather range and export\n",
    "weather_full = load_weather().sort_values(\"datetime\").reset_index(drop=True)\n",
    "wf_features = weather_full[base_feature_cols].copy()\n",
    "wf_features[\"hour\"] = weather_full[\"datetime\"].dt.hour\n",
    "wf_features[\"dayofyear\"] = weather_full[\"datetime\"].dt.dayofyear\n",
    "wf_features[\"hour_sin\"] = np.sin(2 * np.pi * wf_features[\"hour\"] / 24)\n",
    "wf_features[\"hour_cos\"] = np.cos(2 * np.pi * wf_features[\"hour\"] / 24)\n",
    "wf_features[\"doy_sin\"] = np.sin(2 * np.pi * wf_features[\"dayofyear\"] / 365)\n",
    "wf_features[\"doy_cos\"] = np.cos(2 * np.pi * wf_features[\"dayofyear\"] / 365)\n",
    "wf_features[\"rh_x_temp\"] = wf_features[\"relative_humidity_pct\"] * wf_features[\"air_temp_C_weather\"]\n",
    "lag_cols = [\n",
    "    \"diffuse_radiation_Wm2\",\n",
    "    \"global_radiation_Wm2\",\n",
    "    \"direct_radiation_Wm2\",\n",
    "    \"air_temp_C_weather\",\n",
    "    \"relative_humidity_pct\",\n",
    "]\n",
    "for col in lag_cols:\n",
    "    wf_features[f\"{col}_lag1\"] = weather_full[col].shift(1)\n",
    "    wf_features[f\"{col}_lag3\"] = weather_full[col].shift(3)\n",
    "    wf_features[f\"{col}_lag6\"] = weather_full[col].shift(6)\n",
    "    wf_features[f\"{col}_lag18\"] = weather_full[col].shift(18)\n",
    "    wf_features[f\"{col}_lag24\"] = weather_full[col].shift(24)\n",
    "    wf_features[f\"{col}_lag48\"] = weather_full[col].shift(48)\n",
    "    wf_features[f\"{col}_roll3_mean\"] = weather_full[col].rolling(window=3, min_periods=1).mean().shift(1)\n",
    "    wf_features[f\"{col}_roll6_mean\"] = weather_full[col].rolling(window=6, min_periods=1).mean().shift(1)\n",
    "    wf_features[f\"{col}_roll12_mean\"] = weather_full[col].rolling(window=12, min_periods=1).mean().shift(1)\n",
    "    wf_features[f\"{col}_roll24_mean\"] = weather_full[col].rolling(window=24, min_periods=1).mean().shift(1)\n",
    "    wf_features[f\"{col}_roll48_mean\"] = weather_full[col].rolling(window=48, min_periods=1).mean().shift(1)\n",
    "wf_features = wf_features.apply(pd.to_numeric, errors=\"coerce\")\n",
    "wf_features = wf_features.reindex(columns=air_non_empty)\n",
    "air_medians = air_feat[air_non_empty].median()\n",
    "wf_features = wf_features.fillna(air_medians)\n",
    "\n",
    "season_preds = pd.DataFrame({\n",
    "    \"timestamp\": weather_full[\"datetime\"].reset_index(drop=True),\n",
    "    \"pred_air_temp_C\": air_model.predict(wf_features),\n",
    "    \"pred_Rh_internal\": rh_model.predict(wf_features[rh_non_empty].reindex(columns=rh_non_empty)),\n",
    "    \"pred_Eto_mm\": np.maximum(eto_model.predict(wf_features[eto_non_empty].reindex(columns=eto_non_empty)), 0),\n",
    "})\n",
    "season_path = DATA_DIR / \"full_weather_predictions_rh_temp_et0_split.csv\"\n",
    "season_preds.to_csv(season_path, index=False)\n",
    "print(f\"Wrote full weather-range predictions to {season_path}\")\n",
    "season_preds.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
